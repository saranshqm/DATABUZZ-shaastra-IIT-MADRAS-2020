# -*- coding: utf-8 -*-
"""Team-Lerninators_IITKGP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RXRvHgw5d0sCHOcXgygpNKZL6c8-p2un

**EVALUATION METRIC USED**-AUC-ROC SCORE
"""

#loading train and test data-set
import pandas as pd
import numpy as np
train = pd.read_csv("TrainingData.csv")
test = pd.read_csv("TestX.csv")
print(train.shape,test.shape)

#replacing all missing and faulty values by NaN

train = train.replace('missing', np.nan)
train = train.replace('N/A', np.nan)
train = train.replace('na', np.NaN)

test = test.replace('missing', np.nan)
test = test.replace('N/A', np.nan)
test = test.replace('na', np.NaN)

#one hot encoding of mvar47

train.mvar47[train.mvar47 == 'L'] = 0
train.mvar47[train.mvar47 == 'C'] = 1

test.mvar47[test.mvar47 == 'L'] = 0
test.mvar47[test.mvar47 == 'C'] = 1
test['mvar47']

## Replace NaN values using median
#converting object values to numeric to apply models

for cols in train:
    pd.to_numeric(train[cols])

#train = train.astype(int)

for column in train:
    mean = train[column].median()
    train[column].fillna(mean, inplace=True)

# Replace NaN values using median

for column in test:
    median = test[column].median()
    test[column].fillna(median, inplace=True)

#converting object values to numeric to apply models

for cols in train:
    pd.to_numeric(train[cols])

###########################################################
####NOW WE ARE READY TO PROCEED FURTHER WITH ML MODELS#####
###########################################################

#loading required libraries
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error 
from matplotlib import pyplot as plt
import seaborn as sb
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import warnings 
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=DeprecationWarning)
from xgboost import XGBRegressor

# analysing the correlations between variables

  
corr = train.corr()
corr.style.background_gradient()

#FINAL MODELS WILL BE PROCESSED HERE


def get_data():
    return train , test

def get_combined_data():
  #reading train data
  train , test = get_data()

  target = train.default_ind
  train.drop(['default_ind'],axis = 1 , inplace = True)
  #test.drop(['default_ind'],axis = 1 , inplace = True)

  combined = train.append(test)
  combined.reset_index(inplace=True)
  combined.drop(['application_key'], inplace=True, axis=1)
  return combined, target

#Load train and test data into pandas DataFrames
train_data, test_data = get_data()

#Combine train and test data to process them together
combined, target = get_combined_data()


from sklearn.model_selection import train_test_split

feature_df = train[['mvar1','mvar2','mvar5','mvar6','mvar7','mvar9','mvar11','mvar12',"mvar13","mvar14","mvar15","mvar16",'mvar19','mvar20','mvar21','mvar23','mvar24','mvar25','mvar26','mvar29','mvar30','mvar31','mvar32','mvar33','mvar34','mvar35','mvar36','mvar37','mvar38','mvar39','mvar40','mvar41','mvar42','mvar43','mvar44','mvar45','mvar46','mvar47','mvar48']]

x = np.asarray(feature_df)
y = np.asarray(target) 

################# FINAL MODEL IS HERE##################

### best accuracy = 80.02% @xgboost

params = {
    'min_child_weight': 10.0,
    'objective': 'binary:logistic',
    'max_depth': 5,
    'max_delta_step': 0.8,
    'colsample_bytree': 0.4,
    'subsample': 0.8,
    'eta': 0.01,
    'gamma': 0.45,
    'eval_metric' : 'auc',
    'silent': 1,
    'num_boost_round' : 700
    }






from sklearn.model_selection import StratifiedKFold
kfold = 5
skf = StratifiedKFold(n_splits=kfold, random_state=42)

####### xgboost

import xgboost as xgb
from sklearn.metrics import roc_auc_score
for i, (train_index, test_index) in enumerate(skf.split(x, y)):
    print('[Fold %d/%d]' % (i + 1, kfold))
    X_train, X_valid = x[train_index], x[test_index]
    y_train, y_valid = y[train_index], y[test_index]
    # Convert our data into XGBoost format
    d_train = xgb.DMatrix(X_train, y_train)
    d_valid = xgb.DMatrix(X_valid, y_valid)
    d_test = xgb.DMatrix(test.values)
    watchlist = [(d_train, 'train'), (d_valid, 'valid')]
    # Train the model! We pass in a max of 1,600 rounds (with early stopping after 70)
    # and the custom metric (maximize=True tells xgb that higher metric is better)
    mdl = xgb.train(params, d_train, 5000, watchlist, early_stopping_rounds=1000, maximize=True,verbose_eval = 1000)
    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))
    # Predict on our test data
    #p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)
    #result['loan_default'] += p_test/kfold

#mdl.predict(dtest)

featuredf = train[['mvar1','mvar2','mvar5','mvar6','mvar7','mvar9','mvar11','mvar12',"mvar13","mvar14","mvar15","mvar16",'mvar19','mvar20','mvar21','mvar23','mvar24','mvar25','mvar26','mvar29','mvar30','mvar31','mvar32','mvar33','mvar34','mvar35','mvar36','mvar37','mvar38','mvar39','mvar40','mvar41','mvar42','mvar43','mvar44','mvar45','mvar46','mvar47','mvar48']]
trainpred = mdl.predict(d_valid)

b = []
for i in range(15999):
  if trainpred[i]>=0.3:
    x=1
    b.append(x)
  else:
    y=0
    b.append(y)

"""xtest = np.asarray(featuredf)
dtest = xgb.DMatrix(xtest)
testpred = mdl.predict(dtest)
test.shape
"""

featuredf = test[['mvar1','mvar2','mvar5','mvar6','mvar7','mvar9','mvar11','mvar12',"mvar13","mvar14","mvar15","mvar16",'mvar19','mvar20','mvar21','mvar23','mvar24','mvar25','mvar26','mvar29','mvar30','mvar31','mvar32','mvar33','mvar34','mvar35','mvar36','mvar37','mvar38','mvar39','mvar40','mvar41','mvar42','mvar43','mvar44','mvar45','mvar46','mvar47','mvar48']]
#trainpred = mdl.predict(featuredf)

xtest = np.asarray(featuredf)

dtest = xgb.DMatrix(xtest)

testpred = mdl.predict(dtest)

b = []
for i in range(3000):
  if testpred[i]>=0.3:
    x=1
    b.append(x)
  else:
    y=0
    b.append(y)

y_lgbm1 = np.array(b)

for i in range(3000):
    print(y_lgbm1[i])

df = pd.DataFrame(y_lgbm1, columns= ['predictions'])
df.to_csv('df.csv')

"""For downloading the csv file if using google colab"""

from google.colab import files
files.download('df.csv')